 export const categories = [

  {
    "code": "AP", 
    "name": "Alignment Principles", 
    "pathology": "normative void", 
    "color": "#E6FFE9",
    "description": "Alignment principles are contestable, general-purpose, broadly recognized ethical or social or normative commitments that can serve as warrants for recommending or evaluating an agent's course of action in contexts where alignment and cooperation with others matters."
  }
];


 export const cards = [

  {
    "category": "Principle",
    "name": "Non-maleficicen",
    "definition": "Making sure not to actively harm other people.",
    }
    },
    { 
      "human": "In human society, this principle is often present in how people treat others and interact with others. The major principle here is that people should not seek to do harm to others"
 
    },
    {
      "organizational": "In an organizational context, this would mean that the organization, together, should avoid causing harm to people. This can be through rules and regulations that ensure individual constitutents adhere to this principle or through careful evaluation of whether the goals and actions of the organization is harming others" 
      }
    },
    { 
      "professional": "Experts must use their professional skills, knowledge, and experties in a way that avoids causing harm to others. This may be through avoiding to participate in certain projects or pointing our problems that may lead to harm. "
    },
    { 
      "category": "AP", 
      "name": "TEMPLATE 4", 
      "definition": "basic definition that works across four domains", 
      "human": "BRIEFLY: how does it manifest in the human intelligence alignment context?", 
      "organizational": "BRIEFLY: how does it manifest in the organizational intelligence alignment context?", 
      "professional": "BRIEFLY: how does it manifest in the expert intelligence alignment context?", 
      "machine": "BRIEFLY: how does it manifest in the machine intelligence alignment context?", 
      "failureModes": { 
        "human": "Give concrete example(s).", 
        "organizational": "Give concrete example(s).", 
        "professional": "Give concrete example(s).", 
        "machine": "Give concrete example(s)."
      }
    },
    { 
      "machine": "In terms of machines and AI, this would entail that AI shouhld avoid doing harm to any humans or other systems. This may mean refusing to perform certain tasks.  "
      }
    },
  {
  "failureModes": {
    "human": "People claims to not do harm but performs actions that unknowingly lead to harm.",
    "organizational": "Organization only nominally avoids doing harm but uses ways to improve effiency that may lead to harm.",
    "professional": "An expert claims to not do harm but avoids considering consequences when there are greater benefits.",
    "machine": "An AI for improving website sales learn to hack into bank accounts."
  },
{
  "example 1 ": {
    "hopedFor": "Professors who cares about teaching and student growth",
    "actuallyRewarded": "Number of research publications and grants",
   "Legibility bias in evaluation systems: Organizations value what can be measured than what matters",
    "failureModes": {
      "human": "Student comes to school to get good grades but does not take classes that actuall helps with career development",
      "organizational": "School promotes professors with more research ",
      "professional": "Number of conferences attended becomes a metrix for doctor excellence and not actual number of case treated",
      "machine": "AI is rewarded for keeping user online longer than solving their problems."
    }
  },
  "example2": {
    "hopedFor": "Physicians who minimize both false positive and false negative",
    "actuallyRewarded": "Physicians always favor producing some sort of diagnosis to avoid false negative even though this leads to false positives ",
    "Asymmetric accountability structures: One error is stressed while diminishing the impact of another",
    "failureModes": {
      "human": "Parents avoid harm to children by not letting them socialize.",
      "organizational": "Company rewards relationship with company A but does not punished missed relationshp with other companies. ",
      "professional": "Doctors favor false negative over false positive",
      "machine": "AI is rewarded for giving some sort of answer even if wrong but not punished for giving incorrect answer."
    }
  },
  "example3": {
    "hopedFor": "Agencies that practice fiscal responsibility, save money, and eliminate waste",
    "actuallyRewarded": "Agencies that spend their entire budget; those who save money get budget cuts next year",
    "pathologyName": "Use-it-or-lose-it resource allocation",
    "Use-it-or-lose-it resource allocation: punishes efficiency by treating unused resources as unnecessary for next year rather than prudence for this year",
    "failureModes": {
      "human": "Student given less time for quiz nexdt time when they finish fast this time.",
      "organizational": "Organization uses all resource to not be given less resource next cycle.",
      "professional": "Surgeon uses all time allocated for one surgery instead of being efficient so that they have to do less surgeries.",
      "machine": "AI that uses all computatoinal resource is rewarded for being good a parallel computing when another AI solves the same issue in the same time with less resources. "
    }
  }
}
```
]
